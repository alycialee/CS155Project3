{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alyci\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_next(prev_end):\n",
    "    \"\"\"\n",
    "    Find the next end word given previous, finding a similar word that\n",
    "    ends in stressed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        w, p = zip(*word2vec.most_similar(prev_end, topn=10))\n",
    "    except KeyError:\n",
    "        return np.random.choice(inverted_rhyme.keys())\n",
    "\n",
    "    w = list(w)\n",
    "    # Make sure it starts out with unstressed\n",
    "    ends = []\n",
    "    for word in w:\n",
    "        if word == prev_end:\n",
    "            continue\n",
    "        if word not in inverted_rhyme:\n",
    "            continue\n",
    "        ends.append(word)\n",
    "\n",
    "    return np.random.choice(ends)\n",
    "\n",
    "\n",
    "def end_next_volta(prev_end):\n",
    "    try:\n",
    "        w, p = zip(*word2vec.most_similar(positive=[\"rich\", prev_end], \\\n",
    "                                              negative=[\"poor\"], topn=10))\n",
    "    except KeyError:\n",
    "        return np.random.choice(inverted_rhyme.keys())\n",
    "        \n",
    "    w = list(w)\n",
    "    # Make sure it starts out with unstressed\n",
    "    ends = []\n",
    "    for word in w:\n",
    "        if word == prev_end:\n",
    "            continue\n",
    "        if word not in inverted_rhyme:\n",
    "            continue\n",
    "        ends.append(word)\n",
    "\n",
    "    return np.random.choice(ends)\n",
    "\n",
    "\n",
    "def end_next_rhyme(prev_rhyme):\n",
    "    \"\"\"\n",
    "    Find the next end word given previous, and a word that must rhyme \n",
    "    with it.\n",
    "    \"\"\"\n",
    "    ending = inverted_rhyme[prev_rhyme][0]\n",
    "        \n",
    "    rhymes = rhyme[ending]\n",
    "\n",
    "    threshold_similarity = 0.1\n",
    "    best_words = []\n",
    "    for r in rhymes:\n",
    "        if r == prev_rhyme:\n",
    "            continue\n",
    "        try:\n",
    "            sim = word2vec.similarity(prev_rhyme, r)\n",
    "            if sim > threshold_similarity:\n",
    "                best_words.append(r)\n",
    "        except KeyError:\n",
    "            # probably a stopword\n",
    "            best_words.append(r)\n",
    "\n",
    "    if len(best_words) == 0:\n",
    "        return np.random.choice(rhymes)\n",
    "\n",
    "    return np.random.choice(best_words)\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Helper function to sample an index from a probability array\n",
    "    with np.errstate(divide='ignore'):\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "    \n",
    "        preds = np.log(preds) / temperature\n",
    "        \n",
    "        # Fix division by 0\n",
    "        preds[preds == np.inf] = 0\n",
    "\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds =  exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return np.argmax(np.random.multinomial(1, preds, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\alyci\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "\n",
    "d = cmudict.dict()\n",
    "def count_syl(word):\n",
    "    \"\"\" Returns number of syllables in a word. Taken\n",
    "    from StackOverflow. \"\"\"\n",
    "    if word in d:\n",
    "        return len(list(y for y in d[word][0] if y[-1].isdigit()))\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count+=1\n",
    "    if count == 0:\n",
    "        count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sonnets(filename):\n",
    "    \"\"\" Returns entire txt file as string. \"\"\"\n",
    "    str = \"\"\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.isdigit() == False and len(line) > 0:\n",
    "                str += line.lower().translate(str.maketrans('', '', ':;,.?!()')) + \"\\n\"\n",
    "    return str\n",
    "\n",
    "file = 'data/shakespeare.txt'\n",
    "sons = get_sonnets(file)\n",
    "lines = sons.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91006"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', \"'\", '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "# unique chars: 30\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(sons))) # get set of all characters\n",
    "print(chars)\n",
    "print (\"# unique chars: \" + str(len(chars)))\n",
    "\n",
    "# create mapping of characters to unique ids\n",
    "dic_char_to_id = dict((c, i) for i, c in enumerate(chars))\n",
    "dic_id_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "def get_rhyming_words(word, rhyme_data):\n",
    "    for pot_list in rhyme_data:\n",
    "        if word in pot_list:\n",
    "            return pot_list\n",
    "    return []\n",
    "\n",
    "def choose_ending_words(rhyme_data):\n",
    "    temp = copy.deepcopy(rhyme_data)\n",
    "    # choosing rhyming scheme per uniform distribution\n",
    "    choices = [np.random.randint(0, len(rhyme_data)) for _ in range(7)]\n",
    "    words = [''] * 14\n",
    "    ind = 0\n",
    "    for i in [0, 1, 4, 5, 8, 9, 12]:\n",
    "        choice1 = random.choice(temp[choices[ind]])\n",
    "        words[i] = choice1\n",
    "        temp[choices[ind]].remove(choice1)\n",
    "        if i == 12:\n",
    "            choice2 = random.choice(temp[choices[ind]])\n",
    "            words[i+1] = choice2\n",
    "            temp[choices[ind]].remove(choice2)\n",
    "        else:\n",
    "            choice2 = random.choice(temp[choices[ind]])\n",
    "            words[i+2] = choice2\n",
    "            temp[choices[ind]].remove(choice2)\n",
    "        ind += 1\n",
    "    \n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/shakespeare_rhymes.pkl', 'rb') as f:\n",
    "    rhymes = pickle.load(f)\n",
    "    \n",
    "end_words = choose_ending_words(rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', \"'\", '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "# unique chars: 30\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "files = ['data/shakespeare.txt']\n",
    "text = ''\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            #line = re.sub(r'[^\\w\\s]','',line)\n",
    "            line = re.sub(r'[^\\w\\'\\-\\s]','',line)\n",
    "            if len(line) > 0 and not line.isdigit():\n",
    "                text += line.lower() + '\\n'\n",
    "\n",
    "# create mapping of unique chars to integers\n",
    "# chars = sorted(list(set(text)))\n",
    "# print('Total chars:', len(chars))\n",
    "# dic_char_to_id = dict((c, i) for i, c in enumerate(chars))\n",
    "# dic_id_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "chars = sorted(list(set(text))) # get set of all characters\n",
    "print(chars)\n",
    "print (\"# unique chars: \" + str(len(chars)))\n",
    "\n",
    "# create mapping of characters to unique ids\n",
    "dic_char_to_id = dict((c, i) for i, c in enumerate(chars))\n",
    "dic_id_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "leng = 40\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, input_shape=((leng, len(chars)))))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(200, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/new_BACKW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature = 1.0):\n",
    "    ''' Helper function to sample an index from\n",
    "    a probability array. Taken from StackOverflow/\n",
    "    open source code on GitHub. '''\n",
    "\n",
    "    preds = np.asarray(preds).astype('float')\n",
    "    preds = np.log(preds) / temperature\n",
    "    preds[preds == np.inf] = 0\n",
    "\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return np.argmax(np.random.multinomial(1, preds, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to time and and fore and the invited,\n",
      "and time no fore when time and time be dimmed,\n",
      "and and and time no fore that delighted,\n",
      "and the fore thes my loves the untrimmed.\n",
      "eyes to the sence for that i loves the seem,\n",
      "time and and no more my loves the passion,\n",
      "and love and and and therefore when the deem,\n",
      "and and and and and and in the fashion.\n",
      "and that to make and o love and the score,\n",
      "tome and more that me that whose and the charged,\n",
      "and and and and and no love and the store,\n",
      "that fore when in the praised and some enlarged.\n",
      "fore when the fore when that more when the change,\n",
      "that raceous and and that me when the strange.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "son = ''\n",
    "temp = 0.25\n",
    "for i in range(14):\n",
    "    line_prod = ' ' + end_words[i]\n",
    "    line = line_prod\n",
    "    line_prod = line_prod.ljust(leng - 1) + '\\n'\n",
    "    seq = line_prod[::-1]\n",
    "    \n",
    "    while True:\n",
    "        x = np.zeros((1, leng, len(chars)))\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[0, t, dic_char_to_id[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_char = dic_id_to_char[sample(preds, temp)]\n",
    "        \n",
    "        # Ignore special characters\n",
    "        if (next_char == '\\n'):\n",
    "            next_char = ' '\n",
    "\n",
    "        # Check syllables\n",
    "        if (next_char == ' '): \n",
    "            syls = sum([count_syl(str(w)) for w in line.split(' ')])\n",
    "            if syls >= 10:\n",
    "                break\n",
    "        \n",
    "        line = next_char + line\n",
    "        seq = seq[1:] + next_char\n",
    "        \n",
    "    if ((i + 1) % 4 == 0) or (i == 13):\n",
    "        line += '.\\n'\n",
    "    else:\n",
    "        line += ',\\n'\n",
    "        \n",
    "    son += line\n",
    "print(son)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-5e2cd5b4d067>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-5e2cd5b4d067>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    and and and and and and o love the feel,\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "and and and and and and o love the feel,\n",
    "and and and and and that fore in the dross,\n",
    "time and thence for that thence or wist the steel,\n",
    "and and that that me and love and why cross.\n",
    "love's caurest and and and and to lome knit,\n",
    "time and of time and are me when the trim,\n",
    "and that me to time and that my love sit,\n",
    "and and with time and mine eyes to the him.\n",
    "more therefore but whose and that fore the bark,\n",
    "that he in the time in the resemble,\n",
    "and that lace therefore and and and and mark,\n",
    "and and o hate no fore thine assemble.\n",
    "best and and and and that the lest the spring,\n",
    "and time in thine eyes the prefiguring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
