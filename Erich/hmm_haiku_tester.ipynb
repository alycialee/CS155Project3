{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading cmudict: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:749)>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "import pickle\n",
    "from HMM_sol import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pickled preprocessed data\n",
    "\n",
    "file = open('../data/sonnets.pkl', 'rb')\n",
    "sonnets = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/shakespeare_dics.pkl', 'rb')\n",
    "dic_to_ids, dic_to_syl, ids_to_dic, syl_to_dic = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/dic_to_meter.pkl', 'rb')\n",
    "dic_to_meter = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/meter_to_dic.pkl', 'rb')\n",
    "meter_to_dic = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/shakespeare_rhymes.pkl', 'rb')\n",
    "rhyme_data_raw = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# Update rhyming word set to only include words that rhyme, but also end on a stressed syllable\n",
    "# (these will go at the end of lines)\n",
    "temp_rhymes = []\n",
    "\n",
    "for rhyme_set in rhyme_data_raw:\n",
    "    temp_rhyme_set = []\n",
    "    for word in rhyme_set:\n",
    "        if int(dic_to_meter[word][-1]) == 1:\n",
    "            temp_rhyme_set.append(word)\n",
    "    temp_rhymes.append(temp_rhyme_set)\n",
    "\n",
    "rhyme_data_raw = temp_rhymes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_sequential(num_syl, dic_to_syl, dic_to_ids, dic_to_meter, A, O):\n",
    "    temp = np.array(O)\n",
    "    \n",
    "    emission = []\n",
    "    states = []\n",
    "    syllable_count = 0\n",
    "\n",
    "    # choose starting state\n",
    "    y_i = np.random.choice(range(len(O)), p=[1 / len(O) for i in range(len(O))])\n",
    "    \n",
    "    while syllable_count < num_syl:\n",
    "        states.append(y_i)\n",
    "        \n",
    "        # choose a word index\n",
    "        array = range(len(O[y_i]))\n",
    "        observation_index = np.random.choice(array, p=O[y_i])\n",
    "    \n",
    "        # Make sure we don't start off with too many syllables\n",
    "        while (dic_to_syl[ids_to_dic[observation_index]] != 0) and (syllable_count + dic_to_syl[ids_to_dic[observation_index]] > num_syl):\n",
    "            observation_index = np.random.choice(array, p=O[y_i])\n",
    "\n",
    "        word = ids_to_dic[observation_index]\n",
    "\n",
    "        syllable_count += dic_to_syl[word]\n",
    "        emission.append(dic_to_ids[word])\n",
    "        \n",
    "        # change states\n",
    "        array = range(len(A[y_i]))\n",
    "        y_i = np.random.choice(array, p=A[y_i])\n",
    "\n",
    "    return emission, states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_haiku_test(test_HMM, hmm_name):\n",
    "    poem = []\n",
    "\n",
    "    emission, states = generate_emission_sequential(5, dic_to_syl, dic_to_ids, dic_to_meter, test_HMM.A, test_HMM.O)\n",
    "    x = ' '.join([str(ids_to_dic[i]) for i in emission])\n",
    "    poem.append(x)\n",
    "    \n",
    "    emission, states = generate_emission_sequential(7, dic_to_syl, dic_to_ids, dic_to_meter, test_HMM.A, test_HMM.O)\n",
    "    x = ' '.join([str(ids_to_dic[i]) for i in emission])\n",
    "    poem.append(x)\n",
    "    \n",
    "    emission, states = generate_emission_sequential(5, dic_to_syl, dic_to_ids, dic_to_meter, test_HMM.A, test_HMM.O)\n",
    "    x = ' '.join([str(ids_to_dic[i]) for i in emission])\n",
    "    poem.append(x)\n",
    "    \n",
    "    with open('../models/haikus/haiku_{}_sample.txt'.format(hmm_name), 'w+') as f:\n",
    "        for line in poem:\n",
    "            f.write(line)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        for line in poem:\n",
    "            line_syl = []\n",
    "\n",
    "            line_list = line.split()\n",
    "\n",
    "            for word in line_list:\n",
    "                line_syl.append(dic_to_syl[word])\n",
    "            f.write(\"{} {}\".format(line_syl, sum(line_syl)))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        for line in poem:\n",
    "            line_meter = []\n",
    "            line_list = line.split()\n",
    "\n",
    "            for word in line_list:\n",
    "                line_meter.append(dic_to_meter[word])\n",
    "            f.write(str(line_meter))\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_args = [2, 5, 10, 20]\n",
    "num_iter_args = [200]\n",
    "\n",
    "for hidden_state in hidden_state_args:\n",
    "    for num_iter in num_iter_args:\n",
    "        with open('../models/HMM_reversed_hidden_{}_iter_{}.hmm'.format(hidden_state, num_iter), 'rb') as f:\n",
    "            test_HMM = pickle.load(f)\n",
    "            generate_haiku_test(test_HMM, 'reversed_hidden_{}_iter_{}'.format(hidden_state, num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
