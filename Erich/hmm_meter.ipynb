{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading cmudict: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:749)>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "import pickle\n",
    "from HMM_sol import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pickled preprocessed data\n",
    "\n",
    "file = open('../data/sonnets.pkl', 'rb')\n",
    "sonnets = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/shakespeare_dics.pkl', 'rb')\n",
    "dic_to_ids, dic_to_syl, ids_to_dic, syl_to_dic = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/dic_to_meter.pkl', 'rb')\n",
    "dic_to_meter = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/meter_to_dic.pkl', 'rb')\n",
    "meter_to_dic = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/shakespeare_rhymes.pkl', 'rb')\n",
    "rhyme_data_raw = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# Update rhyming word set to only include words that rhyme, but also end on a stressed syllable\n",
    "# (these will go at the end of lines)\n",
    "temp_rhymes = []\n",
    "\n",
    "for rhyme_set in rhyme_data_raw:\n",
    "    temp_rhyme_set = []\n",
    "    for word in rhyme_set:\n",
    "        if int(dic_to_meter[word][-1]) == 1:\n",
    "            temp_rhyme_set.append(word)\n",
    "    temp_rhymes.append(temp_rhyme_set)\n",
    "\n",
    "rhyme_data_raw = temp_rhymes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "tokenized_sonnet = []\n",
    "\n",
    "for i in range(len(sonnets)):\n",
    "    for j in range(len(sonnets[i])):\n",
    "        for k in range(len(sonnets[i][j])):\n",
    "            while len(tokenized_sonnet) < i + 1:\n",
    "                tokenized_sonnet.append([])\n",
    "            while len(tokenized_sonnet[i]) < j + 1:\n",
    "                tokenized_sonnet[i].append([])\n",
    "            while len(tokenized_sonnet[i][j]) < k + 1:\n",
    "                tokenized_sonnet[i][j].append([])\n",
    "            \n",
    "            tokenized_sonnet[i][j][k] = dic_to_ids[sonnets[i][j][k]]\n",
    "            \n",
    "tokenized_sonnet = np.array(tokenized_sonnet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no don't learn rhyme!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first train an HMM to generate sonnets in reverse order\n",
    "reversed_sonnet = []\n",
    "for sonnet in tokenized_sonnet:\n",
    "    for line in sonnet:\n",
    "        line.reverse()\n",
    "        temp = line\n",
    "        reversed_sonnet.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM_reversed_20 = unsupervised_HMM(reversed_sonnet, 20, 10)\n",
    "# with open('../data/HMM_reversed_20.hmm', 'wb+') as f:\n",
    "#     pickle.dump(HMM_reversed_20, f)\n",
    "\n",
    "f = open('../data/HMM_reversed_20.hmm', 'rb')\n",
    "HMM_reversed_20 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate seven pairs of rhyming words without repetition.\n",
    "'''\n",
    "def choose_ending_words(rhyme_data):\n",
    "    temp = copy.deepcopy(rhyme_data)\n",
    "    \n",
    "    index_to_word = {}\n",
    "    \n",
    "    pairs = [(0, 2), (1, 3), (4, 6), (5, 7), (8, 10), (9, 11), (12, 13)]\n",
    "    for i in range(len(pairs)):\n",
    "        # choosing rhyming scheme per uniform distribution\n",
    "        choice = np.random.randint(0, len(temp))\n",
    "        \n",
    "        # We accidentally picked a word that never rhymes with anything else\n",
    "        while len(temp[choice]) <= 1:\n",
    "            choice = np.random.randint(0, len(temp))\n",
    "        \n",
    "        first_index, second_index = pairs[i]\n",
    "        choice1 = random.choice(temp[choice])\n",
    "        temp[choice].remove(choice1)\n",
    "        choice2 = random.choice(temp[choice])\n",
    "        temp[choice].remove(choice2)\n",
    "        \n",
    "        index_to_word[first_index] = choice1\n",
    "        index_to_word[second_index] = choice2\n",
    "    \n",
    "    words = []\n",
    "    for i in range(14):\n",
    "        words.append(index_to_word[i])\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first thing that is int thing in txt\n",
    "meter_data = {}\n",
    "with open(\"../data/Syllable_dictionary.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        temp = line.strip().split(\" \")\n",
    "        word = temp[0]\n",
    "        count = temp[1:]\n",
    "        \n",
    "        for possible_val in count:\n",
    "            if possible_val.isdigit():\n",
    "                meter_data[word] = int(possible_val)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in the form aabb ccdd eeff gg\n",
    "end_words = choose_ending_words(rhyme_data_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in pickled preprocessed data\n",
    "\n",
    "file = open('../data/sonnets.pkl', 'rb')\n",
    "sonnets = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/shakespeare_dics.pkl', 'rb')\n",
    "dic_to_ids, dic_to_syl, ids_to_dic, syl_to_dic = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/dic_to_meter.pkl', 'rb')\n",
    "dic_to_meter = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/meter_to_dic.pkl', 'rb')\n",
    "meter_to_dic = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/shakespeare_rhymes.pkl', 'rb')\n",
    "rhyme_data_raw = pickle.load(file)\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_sequential(num_syl, dic_to_syl, dic_to_ids, dic_to_meter, A, O, start_word):\n",
    "    temp = np.array(O)\n",
    "    most_probable_start_state = np.argmax(temp[:, dic_to_ids[start_word]])\n",
    "    \n",
    "    emission = []\n",
    "    states = []\n",
    "\n",
    "    # choose starting state\n",
    "    y_i = most_probable_start_state\n",
    "    states.append(y_i)\n",
    "    \n",
    "    stress = int(dic_to_meter[start_word][0])\n",
    "        \n",
    "    syllable_count = dic_to_syl[start_word]\n",
    "    emission.append(dic_to_ids[start_word])\n",
    "    \n",
    "    while syllable_count < num_syl:\n",
    "        y_i = int(y_i)\n",
    "        array = range(len(O[y_i]))\n",
    "        observation_index = np.random.choice(array, p=O[y_i])\n",
    "        \n",
    "        while (syllable_count + dic_to_syl[ids_to_dic[observation_index]] > num_syl or\n",
    "               ((dic_to_syl[ids_to_dic[observation_index]] != 0) and (stress == int(dic_to_meter[ids_to_dic[observation_index]][-1])))):\n",
    "            observation_index = np.random.choice(array, p=O[y_i])\n",
    "                    \n",
    "        emission.append(observation_index)\n",
    "        syllable_count += dic_to_syl[ids_to_dic[observation_index]]\n",
    "        \n",
    "        if dic_to_syl[ids_to_dic[observation_index]] != 0:\n",
    "            stress = int(dic_to_meter[ids_to_dic[observation_index]][0])\n",
    "        \n",
    "    return emission, states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = []\n",
    "for i in range(14):\n",
    "    start_state = end_words[i]\n",
    "    emission, states = generate_emission_sequential(10, dic_to_syl, dic_to_ids, dic_to_meter, \n",
    "                                                    HMM_reversed_20.A, HMM_reversed_20.O, start_state)\n",
    "    emission.reverse()\n",
    "    x = ' '.join([str(ids_to_dic[i]) for i in emission])\n",
    "    poem.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ye dearly comment swerving no growing\n",
      "sky bind deceived shaken spacious\n",
      "sets every which feed'st epitaph knowing\n",
      "quick father me injurious draw gracious\n",
      "clears devil foes arising rare amiss\n",
      "wrecked stretched painted thither wrinkles strive\n",
      "fleece teachest jewel and sky other kiss\n",
      "cries twofold habitation lie alive\n",
      "defendant limping gainer beauties used\n",
      "controlling tomb renewest story bow\n",
      "cries sight ye gazeth rage defence abused\n",
      "sky seeing deemed sky deeds directed brow\n",
      "turn meadows seasons penance sullen bent\n",
      "untold assemble cherish discontent\n",
      "\n",
      "\n",
      "[1, 2, 2, 2, 1, 2] 10\n",
      "[1, 1, 3, 2, 3] 10\n",
      "[1, 2, 1, 1, 3, 2] 10\n",
      "[1, 2, 1, 3, 1, 2] 10\n",
      "[1, 2, 1, 3, 1, 2] 10\n",
      "[1, 2, 2, 2, 2, 1] 10\n",
      "[1, 2, 2, 1, 1, 2, 1] 10\n",
      "[1, 2, 4, 1, 2] 10\n",
      "[3, 2, 2, 2, 1] 10\n",
      "[3, 1, 3, 2, 1] 10\n",
      "[1, 1, 1, 2, 1, 2, 2] 10\n",
      "[1, 2, 1, 1, 1, 3, 1] 10\n",
      "[1, 2, 2, 2, 2, 1] 10\n",
      "[2, 3, 2, 3] 10\n",
      "\n",
      "\n",
      "['0', '1, 0', '1, 0', '1, 0', '1', '0, 1']\n",
      "['0', '1', '0, 1, 0', '1, 0', '1, 0, 1']\n",
      "['0', '1, 0', '1', '0', '1, 0, 1', '0, 1']\n",
      "['0', '1, 0', '1', '0, 1, 0', '1', '0, 1']\n",
      "['0', '1, 0', '1', '0, 1, 0', '1', '0, 1']\n",
      "['0', '1, 0', '1, 0', '1, 0', '1, 0', '1']\n",
      "['0', '1, 0', '1, 0', '1', '0', '1, 0', '1']\n",
      "['0', '1, 0', '1, 0, 1, 0', '1', '0, 1']\n",
      "['0, 1, 0', '1, 0', '1, 0', '1, 0', '1']\n",
      "['0, 1, 0', '1', '0, 1, 0', '1, 0', '1']\n",
      "['0', '1', '0', '1, 0', '1', '0, 1', '0, 1']\n",
      "['0', '1, 0', '1', '0', '1', '0, 1, 0', '1']\n",
      "['0', '1, 0', '1, 0', '1, 0', '1, 0', '1']\n",
      "['0, 1', '0, 1, 0', '1, 0', '1, 0, 1']\n"
     ]
    }
   ],
   "source": [
    "for line in poem:\n",
    "    print(line)\n",
    "\n",
    "print(\"\\n\")    \n",
    "\n",
    "for line in poem:\n",
    "    line_syl = []\n",
    "    \n",
    "    line_list = line.split()\n",
    "    \n",
    "    for word in line_list:\n",
    "        line_syl.append(dic_to_syl[word])\n",
    "    print(line_syl, sum(line_syl))\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "for line in poem:\n",
    "    line_meter = []\n",
    "    line_list = line.split()\n",
    "    \n",
    "    for word in line_list:\n",
    "        line_meter.append(dic_to_meter[word])\n",
    "    print(line_meter)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
