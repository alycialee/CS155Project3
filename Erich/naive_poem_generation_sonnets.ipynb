{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/kushaltirumala/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/shakespeare.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "def get_sonnets(filename):\n",
    "    \"\"\" Returns list of separate sonnets in the file. \n",
    "    Each line of a sonnet is a list of words (tokens). \"\"\"\n",
    "    with open(filename) as file:\n",
    "        sons, son = [], []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.isdigit() == False:\n",
    "                lst = line.lower().translate(str.maketrans('', '', ':;,.?!()')).split()\n",
    "                if len(lst) > 0: # count words in line\n",
    "                    son.append(lst)\n",
    "                elif len(son) > 0:\n",
    "                    sons.append(son)\n",
    "                    son = []\n",
    "    sons.append(son) # add the final sonnet\n",
    "    return sons\n",
    "file = '../data/shakespeare.txt'\n",
    "sonnets = get_sonnets(file)\n",
    "\n",
    "# The sonnets 99 and 126 (at indices 98 and 125)\n",
    "# do not count as sonnets, since they are not 14 lines long\n",
    "for i in range(len(sonnets)):\n",
    "    if len(sonnets[i]) != 14:\n",
    "        print(i)\n",
    "        \n",
    "sonnets = sonnets[:98] + sonnets[99:125] + sonnets[126:]\n",
    "\n",
    "d = cmudict.dict()\n",
    "def count_syl(word):\n",
    "    \"\"\" Returns number of syllables in a word. Taken\n",
    "    from StackOverflow. \"\"\"\n",
    "    if word in d:\n",
    "        return len(list(y for y in d[word][0] if y[-1].isdigit()))\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    \n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count+=1\n",
    "    if count == 0:\n",
    "        count +=1\n",
    "    return count\n",
    "\n",
    "def get_syl(dic_to_ids):\n",
    "    \"\"\" Returns dictionary of IDs to syllables given \n",
    "    a dictionary mapping words to ids. \"\"\"\n",
    "    dic = {}\n",
    "    for word in dic_to_ids.keys():\n",
    "        id_ = dic_to_ids[word]\n",
    "        if \"'\" in word:\n",
    "            dic[id_] = 1\n",
    "        else:\n",
    "            dic[id_] = sum(count_syl(w) for w in word.split(\"-\"))\n",
    "        \n",
    "    return dic\n",
    "\n",
    "def get_id(lines):\n",
    "    \"\"\" Returns dictionary of words to IDs and \n",
    "    dictionary of IDs to words. \"\"\"\n",
    "    dic_to_ids, dic_to_words = {}, {}\n",
    "    id_ = 0\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            if word not in dic_to_ids:\n",
    "                dic_to_ids[word] = id_\n",
    "                dic_to_words[id_] = word\n",
    "                id_ += 1\n",
    "    return dic_to_ids, dic_to_words\n",
    "\n",
    "def get_mappings(sonnets, name):\n",
    "    \"\"\" Returns dictionary of words to IDs, dictionary of IDs to words, \n",
    "    and dictionary of IDs to syllables. \"\"\"    \n",
    "    lines = list(itertools.chain.from_iterable(sonnets)) # list of lines\n",
    "    dic_to_ids, dic_to_words = get_id(lines)\n",
    "    dic_syl = get_syl(dic_to_ids)\n",
    "    \n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump((dic_to_ids, dic_to_words, dic_syl), f)\n",
    "    \n",
    "    return dic_to_ids, dic_to_words, dic_syl\n",
    "\n",
    "dic_to_ids, dic_to_words, dic_syl = get_mappings(sonnets, 'shakespeare_dics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_to_dic = {v: k for k,v in dic_to_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "hehe = copy.deepcopy(sonnets)\n",
    "for i in range(len(sonnets)):\n",
    "    for j in range(len(sonnets[i])):\n",
    "        for k in range(len(sonnets[i][j])):\n",
    "            hehe[i][j][k] = dic_to_ids[sonnets[i][j][k]]\n",
    "hehe = np.array(hehe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fin = []\n",
    "for i in range(len(hehe)):\n",
    "    temp = []\n",
    "    for j in range(len(hehe[i])):\n",
    "        for k in range(len(hehe[i][j])):\n",
    "            temp.append(hehe[i][j][k])\n",
    "    fin.append(temp)\n",
    "fin = np.array(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from HMM_sol import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n",
      "Iteration: 110\n",
      "Iteration: 120\n",
      "Iteration: 130\n",
      "Iteration: 140\n",
      "Iteration: 150\n",
      "Iteration: 160\n",
      "Iteration: 170\n",
      "Iteration: 180\n",
      "Iteration: 190\n",
      "Iteration: 200\n"
     ]
    }
   ],
   "source": [
    "HMM10 = unsupervised_HMM(fin, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emission, states = HMM10.generate_emission(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ' '.join([str(ids_to_dic[i]) for i in emission])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me brightness tongue to like as weigh thou long impregnable my all this graces how thee of but have as'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first thing that is int thing in txt\n",
    "meter_data = {}\n",
    "with open(\"../data/Syllable_dictionary.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        temp = line.strip().split(\" \")\n",
    "        word = temp[0]\n",
    "        count = temp[1:]\n",
    "        \n",
    "        for possible_val in count:\n",
    "            if possible_val.isdigit():\n",
    "                meter_data[word] = int(possible_val)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meter_data[\"niggarding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_sonnet = []\n",
    "for _ in range(14):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_emission_sequential(syl_count, A, O):\n",
    "    emission = []\n",
    "    states = []\n",
    "\n",
    "    # choose starting state\n",
    "    y_i = np.random.randint(0, len(A))\n",
    "    states.append(y_i)\n",
    "\n",
    "    counter = 0\n",
    "    while counter < syl_count:\n",
    "        y_i = int(y_i)\n",
    "        # print(len(self.O[y_i]))\n",
    "        array = range(len(O[y_i]))\n",
    "        observation_index = np.random.choice(array, p=O[y_i])\n",
    "        while counter + meter_data[ids_to_dic[observation_index]] > syl_count:\n",
    "#             print(\"uhoh\")\n",
    "            observation_index = np.random.choice(array, p=O[y_i])\n",
    "            \n",
    "        emission.append(observation_index)\n",
    "        counter += meter_data[ids_to_dic[observation_index]]\n",
    "        \n",
    "    return emission, states\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission, states = generate_emission_sequential(10, HMM10.A, HMM10.O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ' '.join([str(ids_to_dic[i]) for i in emission])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elsewhere nights by was but grace to die of'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of numbers thine return idly lives fame\n",
      "will nothing yet not there brief live praise thee\n",
      "soul had was seek saw know strangely if live\n",
      "him you thee me a true if shun so keeps\n",
      "then chance be better faint am no deem toil\n",
      "raised hide admitted i not vacant be\n",
      "spend farther stay not predict think shows have\n",
      "gain face blush sight thee the beauty debate\n",
      "breast other will summer part view slight child\n",
      "best unseeing love this miles hate the those\n",
      "to and with past give nor of of was with\n",
      "most buried all other which that through and\n",
      "closet die might spurring yet i dull it\n",
      "and weak buried though forsake therein life\n"
     ]
    }
   ],
   "source": [
    "for _ in range(14):\n",
    "    emission, states = generate_emission_sequential(10, HMM10.A, HMM10.O)\n",
    "    x = ' '.join([str(ids_to_dic[i]) for i in emission])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_hmm(hmm, filename):\n",
    "    with open(\"models/\"+filename, 'wb') as f:\n",
    "        pickle.dump(hmm, f)\n",
    "save_hmm(HMM10, \"hmm_naive_10_sonnets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
