{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/kushaltirumala/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/shakespeare.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "def get_sonnets(filename):\n",
    "    \"\"\" Returns list of separate sonnets in the file. \n",
    "    Each line of a sonnet is a list of words (tokens). \"\"\"\n",
    "    with open(filename) as file:\n",
    "        sons, son = [], []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.isdigit() == False:\n",
    "                lst = line.lower().translate(str.maketrans('', '', ':;,.?!()')).split()\n",
    "                if len(lst) > 0: # count words in line\n",
    "                    son.append(lst)\n",
    "                elif len(son) > 0:\n",
    "                    sons.append(son)\n",
    "                    son = []\n",
    "    sons.append(son) # add the final sonnet\n",
    "    return sons\n",
    "file = '../data/shakespeare.txt'\n",
    "sonnets = get_sonnets(file)\n",
    "\n",
    "# The sonnets 99 and 126 (at indices 98 and 125)\n",
    "# do not count as sonnets, since they are not 14 lines long\n",
    "for i in range(len(sonnets)):\n",
    "    if len(sonnets[i]) != 14:\n",
    "        print(i)\n",
    "        \n",
    "sonnets = sonnets[:98] + sonnets[99:125] + sonnets[126:]\n",
    "\n",
    "d = cmudict.dict()\n",
    "def count_syl(word):\n",
    "    \"\"\" Returns number of syllables in a word. Taken\n",
    "    from StackOverflow. \"\"\"\n",
    "    if word in d:\n",
    "        return len(list(y for y in d[word][0] if y[-1].isdigit()))\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    \n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count+=1\n",
    "    if count == 0:\n",
    "        count +=1\n",
    "    return count\n",
    "\n",
    "def get_syl(dic_to_ids):\n",
    "    \"\"\" Returns dictionary of IDs to syllables given \n",
    "    a dictionary mapping words to ids. \"\"\"\n",
    "    dic = {}\n",
    "    for word in dic_to_ids.keys():\n",
    "        id_ = dic_to_ids[word]\n",
    "        if \"'\" in word:\n",
    "            dic[id_] = 1\n",
    "        else:\n",
    "            dic[id_] = sum(count_syl(w) for w in word.split(\"-\"))\n",
    "        \n",
    "    return dic\n",
    "\n",
    "def get_id(lines):\n",
    "    \"\"\" Returns dictionary of words to IDs and \n",
    "    dictionary of IDs to words. \"\"\"\n",
    "    dic_to_ids, dic_to_words = {}, {}\n",
    "    id_ = 0\n",
    "    for line in lines:\n",
    "        for word in line:\n",
    "            if word not in dic_to_ids:\n",
    "                dic_to_ids[word] = id_\n",
    "                dic_to_words[id_] = word\n",
    "                id_ += 1\n",
    "    return dic_to_ids, dic_to_words\n",
    "\n",
    "def get_mappings(sonnets, name):\n",
    "    \"\"\" Returns dictionary of words to IDs, dictionary of IDs to words, \n",
    "    and dictionary of IDs to syllables. \"\"\"    \n",
    "    lines = list(itertools.chain.from_iterable(sonnets)) # list of lines\n",
    "    dic_to_ids, dic_to_words = get_id(lines)\n",
    "    dic_syl = get_syl(dic_to_ids)\n",
    "    \n",
    "    with open(name, 'wb') as f:\n",
    "        pickle.dump((dic_to_ids, dic_to_words, dic_syl), f)\n",
    "    \n",
    "    return dic_to_ids, dic_to_words, dic_syl\n",
    "\n",
    "dic_to_ids, dic_to_words, dic_syl = get_mappings(sonnets, 'shakespeare_dics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_to_dic = {v: k for k,v in dic_to_ids.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "hehe = copy.deepcopy(sonnets)\n",
    "for i in range(len(sonnets)):\n",
    "    for j in range(len(sonnets[i])):\n",
    "        for k in range(len(sonnets[i][j])):\n",
    "            hehe[i][j][k] = dic_to_ids[sonnets[i][j][k]]\n",
    "hehe = np.array(hehe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = []\n",
    "for sonnet in hehe:\n",
    "    for line in sonnet:\n",
    "        fin.append(line)\n",
    "fin = np.array(fin)\n",
    "fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n",
      "Iteration: 110\n",
      "Iteration: 120\n",
      "Iteration: 130\n",
      "Iteration: 140\n",
      "Iteration: 150\n",
      "Iteration: 160\n",
      "Iteration: 170\n",
      "Iteration: 180\n",
      "Iteration: 190\n",
      "Iteration: 200\n"
     ]
    }
   ],
   "source": [
    "from HMM_sol import *\n",
    "HMM10 = unsupervised_HMM(fin, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emission, states = HMM10.generate_emission(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ' '.join([str(ids_to_dic[i]) for i in emission])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bloody an stay increase purpose dear most as the receipt'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n",
      "Iteration: 110\n",
      "Iteration: 120\n",
      "Iteration: 130\n",
      "Iteration: 140\n",
      "Iteration: 150\n",
      "Iteration: 160\n",
      "Iteration: 170\n",
      "Iteration: 180\n",
      "Iteration: 190\n",
      "Iteration: 200\n"
     ]
    }
   ],
   "source": [
    "HMM50 = unsupervised_HMM(fin, 20, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emission, states = HMM50.generate_emission(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ' '.join([str(ids_to_dic[i]) for i in emission])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'active to him white and vow unstained thine that then'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take first thing that is int thing in txt\n",
    "meter_data = {}\n",
    "with open(\"../data/Syllable_dictionary.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        temp = line.strip().split(\" \")\n",
    "        word = temp[0]\n",
    "        count = temp[1:]\n",
    "        \n",
    "        for possible_val in count:\n",
    "            if possible_val.isdigit():\n",
    "                meter_data[word] = int(possible_val)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_emission_sequential(syl_count, A, O):\n",
    "    emission = []\n",
    "    states = []\n",
    "\n",
    "    # choose starting state\n",
    "    y_i = np.random.randint(0, len(A))\n",
    "    states.append(y_i)\n",
    "\n",
    "    counter = 0\n",
    "    while counter < syl_count:\n",
    "        y_i = int(y_i)\n",
    "        # print(len(self.O[y_i]))\n",
    "        array = range(len(O[y_i]))\n",
    "        observation_index = np.random.choice(array, p=O[y_i])\n",
    "        while counter + meter_data[ids_to_dic[observation_index]] > syl_count:\n",
    "#             print(\"uhoh\")\n",
    "            observation_index = np.random.choice(array, p=O[y_i])\n",
    "            \n",
    "        emission.append(observation_index)\n",
    "        counter += meter_data[ids_to_dic[observation_index]]\n",
    "        \n",
    "    return emission, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steep-up which dial shape hurt me hence fair\n",
      "thee outward beauty beauty image state\n",
      "my them thy barrenly short come wet the\n",
      "pays in in to found to as with you i\n",
      "eye point writ only will hate hate interest\n",
      "what in pitying added stand that in thee\n",
      "and not doth will beloved respect kindness\n",
      "appeal as aspect and but but fond so\n",
      "love all i from painting on why knowing\n",
      "do hush only all from on bring fire in\n",
      "so i with lends as sing i thinking gold\n",
      "that for watch and even you unlearned why\n",
      "wiry lo shadow so place one other\n",
      "witness and possessed deceased herald\n"
     ]
    }
   ],
   "source": [
    "for _ in range(14):\n",
    "    emission, states = generate_emission_sequential(10, HMM50.A, HMM50.O)\n",
    "    x = ' '.join([str(ids_to_dic[i]) for i in emission])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_hmm(hmm, filename):\n",
    "    with open(\"models/\"+filename, 'wb') as f:\n",
    "        pickle.dump(hmm, f)\n",
    "    \n",
    "save_hmm(HMM50,\"hmm_naive_50_lines.pkl\")\n",
    "save_hmm(HMM10, \"hmm_naive_10_lines.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
